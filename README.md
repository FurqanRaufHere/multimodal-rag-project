# Multimodal Retrieval-Augmented Generation (RAG) System

This repository implements a multimodal Retrieval-Augmented Generation (RAG) system capable of processing and retrieving information from both textual and visual content (e.g., tables, graphs, and charts) within PDF and DOCX documents. The system supports semantic search over text and images, integrates with an LLM (Mistral), and includes a web-based user interface for querying and interaction.

## Features

- Multimodal data extraction from PDF and DOCX (text, tables, images)
- Sentence-BERT and CLIP-based dense embeddings
- FAISS vector indices for efficient retrieval
- Unified semantic search over text and images
- LLM integration with Mistral (CoT, zero-shot, few-shot prompting)
- Web interface with query + image upload support
- Embedding space visualization (t-SNE)

## System Architecture

Documents (PDF/DOCX) <br>
â”‚ <br>
â–¼ <br>
Data Extraction (text, tables, images, OCR, captions) <br>
â”‚ <br>
â–¼ <br>
Embeddings (Sentence-BERT, CLIP) â†’ FAISS indices <br>
â”‚ <br>
â–¼ <br>
Semantic Search (text/image/multimodal queries) <br>
â”‚ <br>
â–¼ <br>
LLM (Mistral) â†’ Answer Generation <br>
â”‚ <br>
â–¼ <br>
Frontend (Flask-based interface) <br>


## Directory Structure

â”œâ”€â”€ data/ # Input documents (PDF, DOCX)
â”œâ”€â”€ output/ # Extracted chunks and images
â”œâ”€â”€ extracted_data/ # Preprocessed chunk pickle
â”œâ”€â”€ embeddings_data/ # FAISS indices and stats
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ extraction/ # data_extraction.py
â”‚ â”œâ”€â”€ embeddings/ # text_image_embeddings.py
â”‚ â”œâ”€â”€ retrieval/ # retrieval.py
â”‚ â”œâ”€â”€ llm/ # llm_integration.py
â”‚ â””â”€â”€ semantic/ # semantic_search.py
â”œâ”€â”€ frontend/ # Flask app and templates
â”œâ”€â”€ prepare_chunks_for_embeddings.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ğŸ› ï¸ Technologies Used

### ğŸ§‘â€ğŸ’» Programming Language
- **Python 3.8+**

### ğŸ“„ Document Processing
- **PyMuPDF** â€“ PDF text, table, and image extraction
- **EasyOCR** â€“ Optical character recognition for text in images
- **Tesseract** â€“ Fallback OCR engine

### ğŸ§  Embedding Models
- **Sentence-BERT** â€“ `all-MiniLM-L6-v2` for textual embeddings
- **CLIP** â€“ `ViT-B/32` for image embeddings
- **BLIP** â€“ Image captioning for descriptive embeddings

### ğŸ” Vector Search
- **FAISS** â€“ Efficient similarity search for high-dimensional vectors

### ğŸ¤– Language Model
- **Mistral LLM API** â€“ For zero-shot, few-shot, and CoT-based answer generation

### ğŸŒ Web Application
- **Flask** â€“ Lightweight backend for chat and file serving

### ğŸ“Š Visualization
- **Matplotlib** â€“ For plotting
- **t-SNE (via scikit-learn)** â€“ Dimensionality reduction for embedding visualization


## Setup Instructions

### 1. Clone the repository


```bash
git clone https://github.com/your-username/multimodal-rag.git
cd multimodal-rag

python -m venv venv  # create the virtual environment
venv\Scripts\activate

pip install -r requirements.txt #install dependencies

```